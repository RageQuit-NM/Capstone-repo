# Capstone-repo
ENSE400/477 Capstone Project

**Team members:**
Shane - co-founder
Bryden - co-founder

**Vlogs:**
Vlog 1 - https://www.youtube.com/watch?v=XvAk2sP1oqM

Vlog 2 - https://www.youtube.com/watch?v=9GwwqNuP7M8

Vlog 3 - https://youtu.be/untYzvhwik8

**Background:**

Toxicity in online environments is nothing new. It is common for players under the guise of online-anonymity to unload their anger and discontent onto anyone who has the misfortune of being queued into their lobby. The negative emotions experienced by those around them lead to negative thoughts about the game, these thoughts in turn lead to more negative emotions etc. etc.. The players who are subject to toxicity are likely to express their new-found negative emotions much like the original perpetrator,  and so the problem spirals out of control. The game environment becomes tense as players fear the potential cascade of negativity they might incur when they queue into a new lobby. As the in-game experience deteriorates the negativity spills over to the surrounding community, players are at war with each other. They call each other varying slurs and insult each other's mothers. Once the community is tainted and the game has a poor reputation it is difficult to recuperate.
As long as there have been toxic players in online games there have also been countermeasures. Some countermeasures that most will recognize include text chat censors, player reporting options, and my personal favorite; vote to kick. Text chat censors do not work for voice comms and nefarious messages will still be typed out with workarounds such as substituting characters and using multiple messages. Reporting options are the worst of the lot as you click the report icon seemingly in vain, a reported player is unlikely to be banned or blocked as it is often difficult to prove the claims of a report. Vote to kick, although seemingly effective, is easy to abuse in order to contribute to toxicity rather than stop it, not to mention how poorly it transfers over to competitive games. At the end of the day these measures are not people centered solutions for a people centered problem. Improving the emotional health of players by providing controls to improve the quality of their time online and analysing their in-game behaviour is a much more daunting but more relevant solution.

**Business need/opportunity:**

Video game addiction, while at times profitable, harms the players that are hooked and damages gaming communities. The desire to reduce gaming addictions is something everyone involved in gaming culture should strive for. Beyond improving the lives of those afflicted, overplay of a given game can lead to player burnout which means the player has played all they can play and move on to a different title. Alternatively, a player may remain on the game and become an increasingly detrimental presence, they can ruin other players in game experience, communicate harmful messages on community platforms, and generally belittle those around them. Tainting a game with such negativity tends to spiral, more and more players become frustrated and become negative community members. Maintaining a healthy community surrounding a game should be on the mind of gamemakers everywhere because toxic communities chase away existing players and dissuade new ones from giving a game a try.

Criticism about gambling-like mechanics is terrifying to all games that employ loot boxes. If this stream of revenue is cut off, many game makers will be taking a serious hit to their wallets. By improving the well being of players and lessening gaming addictions, the chances that loot boxes will remain an unregulated source of income goes up.

The business need for emotional and community wellness controls stems from the fact that players leave games that provide a negative experience. With the trends towards cheap/free-to-play and turning a profit through cosmetic sales and loot boxes this means a player is likely to spend less time in game when they could be making purchases.

**Reason:**

*Why are we designing?*

Video games have become an immensely popular hobby, with millions playing everyday, it is important that we maintain a healthy relationship with this beloved pastime. Having the self control to quit before playing becomes unhealthy can be difficult, playing past this point causes frustration and can lead to outlashes against others in the community. As avid video game enjoyers ourselves, we have experienced these toxic outlashes and want to keep our communities safe from such issues. Our goal is to nurture warm and inviting communities that will thrive. We want to improve the mental wellness of gamers and help them understand the balance between games and life.

**How?**

We are aiming to provide a system that considers player performance, time played, time of day, text chat activity, reports, sanctions, etc. to determine when a player should take a break. When the system decides enough is enough, incentivise players to step away from the game and partake in self care.

**Impact:**

When we are done, video games with toxic experiences will now have healthier, more inviting communities so we think we need to develop a tool available to preserve the mental well being of their players and improve the community surrounding the game.

**Who:**

Our audience is any online game community. Chess, League of Legends, Tom Clany’s Rainbow Six Siege, poker, etc.
Everyone’s opinion matters to us. Users, developers, parents of users in particular.
We want to reach anyone involved in (video) game communities.
Our audience will span across the globe. They get their information through every media available, however, we will likely get information about us and our product to them through video games directly or from other sources within each gaming community

